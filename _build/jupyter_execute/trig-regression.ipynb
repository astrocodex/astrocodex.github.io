{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d58c1f4",
   "metadata": {},
   "source": [
    "# Trigonometric Regression\n",
    ":::{admonition} [Earl Bellinger](https://orcid.org/0000-0003-4456-4863) (Yale University)\n",
    ":class: Author\n",
    "\n",
    "*Description*: A series of exercises at the advanced undergraduate level building up the intuition and practice of usuing trigonometric regression to fit periodically varying data (in this case, classically pulsating Cepheid stars).\n",
    "\n",
    "*Intended Audience*: Advanced Undergraduate / Early Graduate\n",
    "\n",
    "*tags*: `linear-regression`, `penalized-regression`, `feature-selection`, `machine-learning`, `scikit-learn`, `Fourier-analysis`, `data-visualization`, `variable-stars`\n",
    "\n",
    "*Last Updated: July 23, 2024*\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b6c93-1f89-43b8-9c22-7ac0c0f4997e",
   "metadata": {},
   "source": [
    "\n",
    ":::{admonition} Learning Objectives\n",
    ":class: learningobjective\n",
    "1. Create linear regression models \n",
    "2. Understand how to use a different basis (in this case, a trigonometric basis) \n",
    "3. Apply a penalty to the regression model and learn about cross-validation \n",
    "4. Learn about classically pulsating stars: this will enable you to determine exactly how bright a given pulsating star will be at any given time in the past or future! In addition, these statistical models we are fitting are a compact description of the lightcurve, which then enables us to compare observations of a star with a theoretical simulation. That in turn would enable us to determine things about the star, such as its mass, radius, metallicity, and age. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac25232",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Classically pulsating stars such as Cepheids and RR Lyrae stars brighten and dim periodically. \n",
    "\n",
    "Here is an example of a phased lightcurve obtained by the OGLE project of a Cepheid star in the Large Magellanic Cloud: \n",
    "\n",
    "\n",
    "In this series of exercises, we will use linear regression to fit a **trigonometric model** to this phased lightcurve. \n",
    "\n",
    "Lastly, we will use penalized regression for feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad9cdf",
   "metadata": {},
   "source": [
    ":::{admonition} Review of Ordinary Linear Regression\n",
    ":class: dropdown\n",
    "- **Objective**: Predict a dependent variable $\\mathbf{y}$ based on independent variables $X$.\n",
    "- **Model**: $\\begin{align*}\n",
    "    \\mathbf{y} &= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_m X_m + \\epsilon= \\boldsymbol\\beta \\mathbf{X} + \\epsilon \\\\\n",
    "\\end{align*}$\n",
    "\n",
    "where $\\beta_0$ is the intercept, $\\beta_1$ a coefficient, and $\\epsilon$ an error term.\n",
    "- **Loss**: $\\arg\\min_{\\boldsymbol\\beta}||\\mathbf{y} - \\boldsymbol{\\beta} \\mathbf{X}||_2$\n",
    "- **Solution**: $\\boldsymbol{\\hat\\beta} = (\\mathbf{X}^\\mathrm{T}\\mathbf{X})^{-1}\\mathbf{X}^\\mathrm{T}\\mathbf{y}$  (Thanks, Gauss!) \n",
    "\n",
    "**See also**: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff572f-65cf-4faf-a8df-4dbf63669723",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Hubble Constant\n",
    "\n",
    "In this exercise we will use linear regression to derive $H_0$. Below is the 1929 data from Edwin Hubble of Cepheid-host galaxies, which made him conclude that the Universe is expanding: \n",
    "```\n",
    "distances = np.array([0.21, 0.26, 0.27, 0.27, 0.45, 0.5, 0.8, 1.1, 1.4, 2.0]) # Mpc\n",
    "velocities = np.array([130, 70, 185, 220, 200, 270, 300, 450, 500, 800]) # km/s\n",
    "```\n",
    "\n",
    ":::{exercise}\n",
    ":class: dropdown\n",
    "\n",
    "\n",
    "1. Make a plot of velocity vs. distance \n",
    "2. Obtain and plot the best fit line using ordinary linear regression (**hint**: use `sklearn`)\n",
    "3. What Hubble constant does one find from these data? What does this imply about the age of the Universe, and how does this compare to modern values? \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a695b1-da0d-4e16-bd0c-4e45724602bb",
   "metadata": {},
   "source": [
    "## 3D Linear Model\n",
    "\n",
    "In this exercise, we will practice generating data from a linear model (with noise) and visualizing it. We'll then use the `sklearn` library to fit a linear model to the data.\n",
    "\n",
    ":::{exercise}\n",
    ":class: dropdown\n",
    "Generate random data according to the linear model \n",
    "\n",
    "$$\n",
    "y = 5 + 3x_1 + 2x_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "where $x_1$ and $x_2$ are uniform random variables, and $\\epsilon$ is a normal random variable. \n",
    "\n",
    "1. Generate 100 data points according to this model. \n",
    "2. Plot $y$ vs $x_1$ and $y$ vs $x_2$. \n",
    "3. Make a 3D plot of these three variables. Visualize the data as points and the model as a plane. \n",
    "**Extra credit**: use ipywidgets to control the orientation of the 3D plot. \n",
    "4. Use `sklearn` to fit a linear model to your data. \n",
    "5. Add the plane of best fit to your 3D plot. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c7f32-5754-4414-a832-142fa392493c",
   "metadata": {},
   "source": [
    "## Cepheid Lightcurves \n",
    "\n",
    "We can now use the techniques we've practiced thus far to begin an investigation of the light curves (magnitude vs. time) of classically pulsating Cepheid stars.\n",
    "\n",
    ":::{exercise}\n",
    ":class: dropdown\n",
    "\n",
    "1. Download Cepheid data from the OGLE database: `https://ogledb.astrouw.edu.pl/~ogle/OCVS/data/I/12/OGLE-LMC-CEP-0012.dat`.\n",
    "2. Plot magnitude vs. time (with appropriate errorbars). \n",
    "3. Plot magnitude vs. phase (with appropriate errorbars) by phasing the times according to the pulsation period of 2.6601839 days. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e64775-2bb6-4af4-8a47-73c083ed06f7",
   "metadata": {},
   "source": [
    "## Trigonometric Regression \n",
    "\n",
    "Finally, we can apply trigonometric (a.k.a. sinusoidal) regression to investigate the relevant parameters of our Cepheids. A short review of the technique can be found in the dropdown.\n",
    "\n",
    ":::{exercise}\n",
    ":class: dropdown\n",
    "\n",
    "1. Fit a trigonometric linear regression model to the Cepheid observations \n",
    "2. Plot the fitted model with the data \n",
    "3. Use an ipython widget to adjust the number of parameters in the fit (and to update the plot) \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37ab14-2d65-4aa5-9835-184709f8e9b3",
   "metadata": {},
   "source": [
    ":::{admonition} Review of Trigonometric Regression\n",
    ":class: dropdown\n",
    "\n",
    "When dealing with periodic data, we can change our basis to\n",
    "\n",
    "$$\n",
    "    y(t) = y_0 + \\sum_k^{k_{\\max}} S_k \\sin(k\\omega t) + C_k \\cos(k\\omega t)\n",
    "$$\n",
    "\n",
    "where \n",
    "- $y$ is our (observed) timeseries\n",
    "- $y_0$ is a mean value\n",
    "- $t$ are the time points at which we have data\n",
    "- $\\omega$ is the main frequency of variability (assumed here to be known)\n",
    "- $k\\geq 1$ tells us how many terms are in our fit\n",
    "- and we fit for the amplitudes $S,C$.\n",
    "\n",
    "Note that if $\\omega$ is known, then $y$ is **linear** in $\\mathbf{S, C}$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15839877-b83b-4de1-9693-809c149862cf",
   "metadata": {},
   "source": [
    "## Penalized Regressions\n",
    "\n",
    "It can be beneficial to regularize / penalize the fitting process. Here we will use two common methods: LASSO (L1) and Ridge (L2) regularization, and we'll use cross-validation to determine the best penalty to choose. (For a review on cross-validation, see [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html))\n",
    "\n",
    ":::{exercise}\n",
    ":class: dropdown\n",
    "\n",
    "1. Use a penalized regression model to fit the Cepheid data \n",
    "2. Use an ipython widget to adjust the penalty (and to update the plot)\n",
    "3. Use cross-validation to determine the optimal penalty (and plot it)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87927b4-3090-4819-a578-7439be23b061",
   "metadata": {},
   "source": [
    ":::{admonition} Review of Penalized Regression: LASSO (L1 Regularization)\n",
    ":class: dropdown\n",
    "\n",
    "\n",
    "*a.k.a. least absolute shrinkage and selection operator*\n",
    "\n",
    "- **Objective**: Eliminate less important features\n",
    "- **Model**: Add a penalty term $\\alpha \\sum_{i=1}^{n} |\\beta_i|$ to the loss function\n",
    "\n",
    "Higher $\\alpha$ → more penalty → more coefficients set to zero\n",
    "\n",
    "- **Loss**: $\\arg\\min_{\\boldsymbol\\beta}||\\mathbf{y} - \\boldsymbol{\\beta} \\mathbf{X}||_2 + \\alpha \\sum_{i=1}^{n} |\\beta_i|$\n",
    "- **Solution**: No closed form! Need to search. \n",
    "\n",
    "Takehome message: **LASSO** completely eliminates some features.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1b999-30b2-4f11-b0aa-90d6ca82bd69",
   "metadata": {},
   "source": [
    ":::{admonition} Review of Penalized Regression: Ridge (L2 Regularization)\n",
    ":class: dropdown\n",
    "\n",
    "\n",
    "*a.k.a. Tikhonov regularization*\n",
    "\n",
    "- **Objective**: Minimize the impact of less important features\n",
    "\n",
    "- **Model**: Add a penalty term $\\alpha \\sum_{i=1}^{n} \\beta_i^2$ to the loss function\n",
    "\n",
    "- **Loss**: $\\arg\\min_{\\boldsymbol\\beta}||\\mathbf{y} - \\boldsymbol{\\beta} \\mathbf{X}||_2 + \\alpha \\sum_{i=1}^{n} \\beta_i^2$\n",
    "\n",
    "where $\\alpha$ is a regularization penalty. Higher $\\alpha$ → more penalty → smaller coefficients\n",
    "- **Solution**: $\\boldsymbol{\\hat\\beta} = (\\mathbf{X}^\\mathrm{T}\\mathbf{X} + \\alpha \\mathbf{I})^{-1}\\mathbf{X}^\\mathrm{T}\\mathbf{y}$\n",
    "\n",
    "where $\\mathbf{I}$ is the identity matrix. \n",
    "\n",
    "Takehome message: **Ridge** reduces the magnitude of coefficients, but doesn't set them to zero.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33f166-26a7-4c12-a89b-bdcc87bc9a3b",
   "metadata": {},
   "source": [
    ":::{exercise}\n",
    ":class: dropdown\n",
    "\n",
    "1. Download the lightcurves of more Cepheids \n",
    "2. Fit penalized regression models to them \n",
    "3. Peform exploratory data analysis to find the relationships between the period, amplitudes, etc. \n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}